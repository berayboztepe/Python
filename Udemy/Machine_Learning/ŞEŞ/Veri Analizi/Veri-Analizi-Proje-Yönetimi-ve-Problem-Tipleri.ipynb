{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd#verileri düzenlemek, veriçerçeveleri oluşturmak vb. için kullanılan kütüphane\n",
    "import numpy as np#büyük sayılar ve hesaplama işlemleri\n",
    "import matplotlib.pyplot as plt#çizim için\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "#veriler 2'ye ayrılır:\n",
    "#1-Sayısal = yaş, kilo, boy gibi sayısal veriler(bu örnek için)\n",
    "#2-Kategorik = ulke, cinsiyet gibi sayısal olmayan, evet-hayır, tr-fr gibi veriler(bu örnek için)\n",
    "datas = pd.read_csv('veriler.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ulke  boy  kilo   yas cinsiyet\n",
      "0    tr  130    30  10.0        e\n",
      "1    tr  125    36  11.0        e\n",
      "2    tr  135    34  10.0        k\n",
      "3    tr  133    30   9.0        k\n",
      "4    tr  129    38  12.0        e\n",
      "5    tr  180    90  30.0        e\n",
      "6    tr  190    80  25.0        e\n",
      "7    tr  175    90  35.0        e\n",
      "8    tr  177    60  22.0        k\n",
      "9    us  185   105  33.0        e\n",
      "10   us  165    55  27.0        k\n",
      "11   us  155    50  44.0        k\n",
      "12   us  160    58   NaN        k\n",
      "13   us  162    59  41.0        k\n",
      "14   us  167    62  55.0        k\n",
      "15   fr  174    70  47.0        e\n",
      "16   fr  193    90   NaN        e\n",
      "17   fr  187    80  27.0        e\n",
      "18   fr  183    88  28.0        e\n",
      "19   fr  159    40  29.0        k\n",
      "20   fr  164    66  32.0        k\n",
      "21   fr  166    56  42.0        k\n"
     ]
    }
   ],
   "source": [
    "print(datas)\n",
    "datas1 = datas.copy()\n",
    "datas2 = datas.copy()\n",
    "datas3 = datas.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ulke  boy  kilo    yas cinsiyet\n",
      "0    tr  130    30  10.00        e\n",
      "1    tr  125    36  11.00        e\n",
      "2    tr  135    34  10.00        k\n",
      "3    tr  133    30   9.00        k\n",
      "4    tr  129    38  12.00        e\n",
      "5    tr  180    90  30.00        e\n",
      "6    tr  190    80  25.00        e\n",
      "7    tr  175    90  35.00        e\n",
      "8    tr  177    60  22.00        k\n",
      "9    us  185   105  33.00        e\n",
      "10   us  165    55  27.00        k\n",
      "11   us  155    50  44.00        k\n",
      "12   us  160    58  28.45        k\n",
      "13   us  162    59  41.00        k\n",
      "14   us  167    62  55.00        k\n",
      "15   fr  174    70  47.00        e\n",
      "16   fr  193    90  28.45        e\n",
      "17   fr  187    80  27.00        e\n",
      "18   fr  183    88  28.00        e\n",
      "19   fr  159    40  29.00        k\n",
      "20   fr  164    66  32.00        k\n",
      "21   fr  166    56  42.00        k\n"
     ]
    }
   ],
   "source": [
    "#eksik veriler üzerinde işlemler\n",
    "#eksik verileri yas sütununun ortalaması ile doldurma\n",
    "mean = datas['yas'].mean()\n",
    "datas = datas.fillna(mean)\n",
    "print(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[130.    30.    10.  ]\n",
      " [125.    36.    11.  ]\n",
      " [135.    34.    10.  ]\n",
      " [133.    30.     9.  ]\n",
      " [129.    38.    12.  ]\n",
      " [180.    90.    30.  ]\n",
      " [190.    80.    25.  ]\n",
      " [175.    90.    35.  ]\n",
      " [177.    60.    22.  ]\n",
      " [185.   105.    33.  ]\n",
      " [165.    55.    27.  ]\n",
      " [155.    50.    44.  ]\n",
      " [160.    58.    28.45]\n",
      " [162.    59.    41.  ]\n",
      " [167.    62.    55.  ]\n",
      " [174.    70.    47.  ]\n",
      " [193.    90.    28.45]\n",
      " [187.    80.    27.  ]\n",
      " [183.    88.    28.  ]\n",
      " [159.    40.    29.  ]\n",
      " [164.    66.    32.  ]\n",
      " [166.    56.    42.  ]]\n"
     ]
    }
   ],
   "source": [
    "#eksik verileri yas sütununun ortalaması ile doldurma v2\n",
    "#bu yöntemle sadece dizi üzerinde doldurma işlemi yapılır\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')#nan olan verileri tamamlamak(np.nan), yani nan veriler tamamlanacak\n",
    "#strategy ile de o nan değerler yerine meanlerin yazılacağı\n",
    "Yas = datas1.iloc[:,1:4].values#yaş kolonunu çekeceğiz. [:,1:4] = :, tüm satırların gelmesi için. 1:4 kolonları getir\n",
    "imputer = imputer.fit(Yas[:,1:4])#Öğrenilecek değer(eğitmek için kullanılır). yani kolonların ortalama değerlerini öğrenecek\n",
    "Yas[:,1:4] = imputer.transform(Yas[:,1:4])#burada ise nan değerlerin yerine değer ataması uygula. Yani ortalamayı yaz nan değerler yerine\n",
    "print(Yas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ulke        0.0\n",
      "boy         0.0\n",
      "kilo        0.0\n",
      "yas         9.090909\n",
      "cinsiyet    0.0\n",
      "dtype: float64\n",
      "   ulke  boy  kilo   yas cinsiyet\n",
      "0    tr  130    30  10.0        e\n",
      "1    tr  125    36  11.0        e\n",
      "2    tr  135    34  10.0        k\n",
      "3    tr  133    30   9.0        k\n",
      "4    tr  129    38  12.0        e\n",
      "5    tr  180    90  30.0        e\n",
      "6    tr  190    80  25.0        e\n",
      "7    tr  175    90  35.0        e\n",
      "8    tr  177    60  22.0        k\n",
      "9    us  185   105  33.0        e\n",
      "10   us  165    55  27.0        k\n",
      "11   us  155    50  44.0        k\n",
      "12   us  160    58   NaN        k\n",
      "13   us  162    59  41.0        k\n",
      "14   us  167    62  55.0        k\n",
      "15   fr  174    70  47.0        e\n",
      "16   fr  193    90   NaN        e\n",
      "17   fr  187    80  27.0        e\n",
      "18   fr  183    88  28.0        e\n",
      "19   fr  159    40  29.0        k\n",
      "20   fr  164    66  32.0        k\n",
      "21   fr  166    56  42.0        k\n",
      "\n",
      "Satır düşürülmüş hali\n",
      "\n",
      "    ulke  boy  kilo   yas cinsiyet\n",
      "0    tr  130    30  10.0        e\n",
      "1    tr  125    36  11.0        e\n",
      "2    tr  135    34  10.0        k\n",
      "3    tr  133    30   9.0        k\n",
      "4    tr  129    38  12.0        e\n",
      "5    tr  180    90  30.0        e\n",
      "6    tr  190    80  25.0        e\n",
      "7    tr  175    90  35.0        e\n",
      "8    tr  177    60  22.0        k\n",
      "9    us  185   105  33.0        e\n",
      "10   us  165    55  27.0        k\n",
      "11   us  155    50  44.0        k\n",
      "13   us  162    59  41.0        k\n",
      "14   us  167    62  55.0        k\n",
      "15   fr  174    70  47.0        e\n",
      "17   fr  187    80  27.0        e\n",
      "18   fr  183    88  28.0        e\n",
      "19   fr  159    40  29.0        k\n",
      "20   fr  164    66  32.0        k\n",
      "21   fr  166    56  42.0        k\n"
     ]
    }
   ],
   "source": [
    "#eksik verilerle uğraşmamak için bir diğer yöntem: eğer eksik veri çok yok ve veriye fazla etki etmeyecek gibiyse\n",
    "#eksik verilerin olduğu satıları komple silebiliriz\n",
    "#burada 2 tane eksik veri bulunan satır olduğu için o 2 satırı silmemiz bize:\n",
    "print(datas2.isna().sum() / datas2.shape[0] * 100)# %9'luk bir veri kaybı yaşatacak. O zaman bu 2 satırı silelim\n",
    "print(datas2)\n",
    "datas2 = datas2.dropna()\n",
    "print(\"\\nSatır düşürülmüş hali\\n\\n\", datas2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ulkelere Label Encoder Yapılmış Hali(hepsine sayı verildi)\n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      "\n",
      "\n",
      "\n",
      "Ulkelerin Doğruluk Tablosu Haline Getirilimiş Hali\n",
      " [[0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "\n",
      "\n",
      "\n",
      "Cinsiyete One-Hot Encoder Yapılmış Hali\n",
      " [[1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "#Elimizdeki kategorik verileri sayısal değerlere çevirebiliriz\n",
    "#Ancak buradaki ülke değerlerini sayısal bir veriye çevirdiğimiz zaman sorun çıkabilir: TR=1, US=2, FR=3 diyelim\n",
    "#buradan baktığımızda us, tr'nin 2 katı vb. bir kıyaslama ortaya çıkıyor veya fr = us+tr gibi bir olay ortaya çıkıyor ancak\n",
    "#bu değerler arasında böyle bir kıyaslama yapamayız. Onun için sayısal verilere çevirmek çok mantıklı olmaz\n",
    "#ancak cinsiyeti çevirebiliriz. E=0, K=1 gibi yaparak(kadın-erkek, evet-hayır vb. olduğu için 0-1 kodlama yapılabilir)\n",
    "#Ülke değerleri için: bir 3'lü doğruluk tablosu yaparız. Ulke tr olan biri için doğruluk tablosunda: tr=1, us=0, fr=0 gibi\n",
    "#bir değerlendirme yapabiliriz. Us biri için: tr=0, us=1, fr=0; fr biri için: tr=0, us=0, fr=1\n",
    "#Öncelikle Label Encoding yöntemi: yani Ulkeler\n",
    "\n",
    "ulke=datas1.iloc[:,0:1].values\n",
    "le = preprocessing.LabelEncoder()#bu yöntemle farklı değerler için farklı sayı atamaları yapılıyor(bu örnek için tr=1,us=2,fr=0)\n",
    "ulke[:,0] = le.fit_transform(datas1.iloc[:,0])#burada ise fit ve transform işlemlerini tek seferde yapıyoruz(bir üstte ayrı ayrı yapmıştık)\n",
    "print(\"Ulkelere Label Encoder Yapılmış Hali(hepsine sayı verildi)\\n\",ulke)\n",
    "\n",
    "#sonra One-Hot Encoding uygulayarak doğruluk tablosu haline getiriyoruz. Ulke kısmı için yapılan işlemler tamam\n",
    "ohe = preprocessing.OneHotEncoder()\n",
    "ulke = ohe.fit_transform(ulke).toarray()#sonuç numpy array olarak yazılıyor\n",
    "print(\"\\n\\n\\nUlkelerin Doğruluk Tablosu Haline Getirilimiş Hali\\n\", ulke)\n",
    "\n",
    "\n",
    "#Cinsiyet kısmına da one-hot encoding yapalım. Yalnız burada reshape yapmamızın sebebi:\n",
    "#normalde bu veriyi (1,n)'lik bir array olarak döndürüyor ancak bizim işlem yapabilmemiz için bu arrayin (n, 1) olması lazım\n",
    "cinsiyet = datas3.iloc[:, -1].values.reshape(-1, 1)\n",
    "ohe = preprocessing.OneHotEncoder()\n",
    "cinsiyet = ohe.fit_transform(cinsiyet).toarray()\n",
    "print(\"\\n\\n\\nCinsiyete One-Hot Encoder Yapılmış Hali\\n\", cinsiyet)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ulkeler dfsi\n",
      "      fr   tr  usa\n",
      "0   0.0  1.0  0.0\n",
      "1   0.0  1.0  0.0\n",
      "2   0.0  1.0  0.0\n",
      "3   0.0  1.0  0.0\n",
      "4   0.0  1.0  0.0\n",
      "5   0.0  1.0  0.0\n",
      "6   0.0  1.0  0.0\n",
      "7   0.0  1.0  0.0\n",
      "8   0.0  1.0  0.0\n",
      "9   0.0  0.0  1.0\n",
      "10  0.0  0.0  1.0\n",
      "11  0.0  0.0  1.0\n",
      "12  0.0  0.0  1.0\n",
      "13  0.0  0.0  1.0\n",
      "14  0.0  0.0  1.0\n",
      "15  1.0  0.0  0.0\n",
      "16  1.0  0.0  0.0\n",
      "17  1.0  0.0  0.0\n",
      "18  1.0  0.0  0.0\n",
      "19  1.0  0.0  0.0\n",
      "20  1.0  0.0  0.0\n",
      "21  1.0  0.0  0.0\n",
      "\n",
      "\n",
      "Boy, Kilo, Yas dfsi\n",
      "       boy   kilo    yas\n",
      "0   130.0   30.0  10.00\n",
      "1   125.0   36.0  11.00\n",
      "2   135.0   34.0  10.00\n",
      "3   133.0   30.0   9.00\n",
      "4   129.0   38.0  12.00\n",
      "5   180.0   90.0  30.00\n",
      "6   190.0   80.0  25.00\n",
      "7   175.0   90.0  35.00\n",
      "8   177.0   60.0  22.00\n",
      "9   185.0  105.0  33.00\n",
      "10  165.0   55.0  27.00\n",
      "11  155.0   50.0  44.00\n",
      "12  160.0   58.0  28.45\n",
      "13  162.0   59.0  41.00\n",
      "14  167.0   62.0  55.00\n",
      "15  174.0   70.0  47.00\n",
      "16  193.0   90.0  28.45\n",
      "17  187.0   80.0  27.00\n",
      "18  183.0   88.0  28.00\n",
      "19  159.0   40.0  29.00\n",
      "20  164.0   66.0  32.00\n",
      "21  166.0   56.0  42.00\n",
      "\n",
      "\n",
      "Cinsiyet dfsi\n",
      "    cinsiyet\n",
      "0         e\n",
      "1         e\n",
      "2         k\n",
      "3         k\n",
      "4         e\n",
      "5         e\n",
      "6         e\n",
      "7         e\n",
      "8         k\n",
      "9         e\n",
      "10        k\n",
      "11        k\n",
      "12        k\n",
      "13        k\n",
      "14        k\n",
      "15        e\n",
      "16        e\n",
      "17        e\n",
      "18        e\n",
      "19        k\n",
      "20        k\n",
      "21        k\n",
      "\n",
      "\n",
      "Cinsiyet OHE dfsi\n",
      "     erkek  kiz\n",
      "0     1.0  0.0\n",
      "1     1.0  0.0\n",
      "2     0.0  1.0\n",
      "3     0.0  1.0\n",
      "4     1.0  0.0\n",
      "5     1.0  0.0\n",
      "6     1.0  0.0\n",
      "7     1.0  0.0\n",
      "8     0.0  1.0\n",
      "9     1.0  0.0\n",
      "10    0.0  1.0\n",
      "11    0.0  1.0\n",
      "12    0.0  1.0\n",
      "13    0.0  1.0\n",
      "14    0.0  1.0\n",
      "15    1.0  0.0\n",
      "16    1.0  0.0\n",
      "17    1.0  0.0\n",
      "18    1.0  0.0\n",
      "19    0.0  1.0\n",
      "20    0.0  1.0\n",
      "21    0.0  1.0\n",
      "\n",
      "\n",
      "Ulke ve Boy, Kilo, Yas dfsi\n",
      "      fr   tr  usa    boy   kilo    yas\n",
      "0   0.0  1.0  0.0  130.0   30.0  10.00\n",
      "1   0.0  1.0  0.0  125.0   36.0  11.00\n",
      "2   0.0  1.0  0.0  135.0   34.0  10.00\n",
      "3   0.0  1.0  0.0  133.0   30.0   9.00\n",
      "4   0.0  1.0  0.0  129.0   38.0  12.00\n",
      "5   0.0  1.0  0.0  180.0   90.0  30.00\n",
      "6   0.0  1.0  0.0  190.0   80.0  25.00\n",
      "7   0.0  1.0  0.0  175.0   90.0  35.00\n",
      "8   0.0  1.0  0.0  177.0   60.0  22.00\n",
      "9   0.0  0.0  1.0  185.0  105.0  33.00\n",
      "10  0.0  0.0  1.0  165.0   55.0  27.00\n",
      "11  0.0  0.0  1.0  155.0   50.0  44.00\n",
      "12  0.0  0.0  1.0  160.0   58.0  28.45\n",
      "13  0.0  0.0  1.0  162.0   59.0  41.00\n",
      "14  0.0  0.0  1.0  167.0   62.0  55.00\n",
      "15  1.0  0.0  0.0  174.0   70.0  47.00\n",
      "16  1.0  0.0  0.0  193.0   90.0  28.45\n",
      "17  1.0  0.0  0.0  187.0   80.0  27.00\n",
      "18  1.0  0.0  0.0  183.0   88.0  28.00\n",
      "19  1.0  0.0  0.0  159.0   40.0  29.00\n",
      "20  1.0  0.0  0.0  164.0   66.0  32.00\n",
      "21  1.0  0.0  0.0  166.0   56.0  42.00\n",
      "\n",
      "\n",
      "Bu dfye Cinsiyet eklenmiş halde son df\n",
      "      fr   tr  usa    boy   kilo    yas cinsiyet\n",
      "0   0.0  1.0  0.0  130.0   30.0  10.00        e\n",
      "1   0.0  1.0  0.0  125.0   36.0  11.00        e\n",
      "2   0.0  1.0  0.0  135.0   34.0  10.00        k\n",
      "3   0.0  1.0  0.0  133.0   30.0   9.00        k\n",
      "4   0.0  1.0  0.0  129.0   38.0  12.00        e\n",
      "5   0.0  1.0  0.0  180.0   90.0  30.00        e\n",
      "6   0.0  1.0  0.0  190.0   80.0  25.00        e\n",
      "7   0.0  1.0  0.0  175.0   90.0  35.00        e\n",
      "8   0.0  1.0  0.0  177.0   60.0  22.00        k\n",
      "9   0.0  0.0  1.0  185.0  105.0  33.00        e\n",
      "10  0.0  0.0  1.0  165.0   55.0  27.00        k\n",
      "11  0.0  0.0  1.0  155.0   50.0  44.00        k\n",
      "12  0.0  0.0  1.0  160.0   58.0  28.45        k\n",
      "13  0.0  0.0  1.0  162.0   59.0  41.00        k\n",
      "14  0.0  0.0  1.0  167.0   62.0  55.00        k\n",
      "15  1.0  0.0  0.0  174.0   70.0  47.00        e\n",
      "16  1.0  0.0  0.0  193.0   90.0  28.45        e\n",
      "17  1.0  0.0  0.0  187.0   80.0  27.00        e\n",
      "18  1.0  0.0  0.0  183.0   88.0  28.00        e\n",
      "19  1.0  0.0  0.0  159.0   40.0  29.00        k\n",
      "20  1.0  0.0  0.0  164.0   66.0  32.00        k\n",
      "21  1.0  0.0  0.0  166.0   56.0  42.00        k\n",
      "\n",
      "\n",
      "Tek seferde oluşturulmuş df\n",
      "      fr   tr  usa    boy   kilo    yas cinsiyet\n",
      "0   0.0  1.0  0.0  130.0   30.0  10.00        e\n",
      "1   0.0  1.0  0.0  125.0   36.0  11.00        e\n",
      "2   0.0  1.0  0.0  135.0   34.0  10.00        k\n",
      "3   0.0  1.0  0.0  133.0   30.0   9.00        k\n",
      "4   0.0  1.0  0.0  129.0   38.0  12.00        e\n",
      "5   0.0  1.0  0.0  180.0   90.0  30.00        e\n",
      "6   0.0  1.0  0.0  190.0   80.0  25.00        e\n",
      "7   0.0  1.0  0.0  175.0   90.0  35.00        e\n",
      "8   0.0  1.0  0.0  177.0   60.0  22.00        k\n",
      "9   0.0  0.0  1.0  185.0  105.0  33.00        e\n",
      "10  0.0  0.0  1.0  165.0   55.0  27.00        k\n",
      "11  0.0  0.0  1.0  155.0   50.0  44.00        k\n",
      "12  0.0  0.0  1.0  160.0   58.0  28.45        k\n",
      "13  0.0  0.0  1.0  162.0   59.0  41.00        k\n",
      "14  0.0  0.0  1.0  167.0   62.0  55.00        k\n",
      "15  1.0  0.0  0.0  174.0   70.0  47.00        e\n",
      "16  1.0  0.0  0.0  193.0   90.0  28.45        e\n",
      "17  1.0  0.0  0.0  187.0   80.0  27.00        e\n",
      "18  1.0  0.0  0.0  183.0   88.0  28.00        e\n",
      "19  1.0  0.0  0.0  159.0   40.0  29.00        k\n",
      "20  1.0  0.0  0.0  164.0   66.0  32.00        k\n",
      "21  1.0  0.0  0.0  166.0   56.0  42.00        k\n",
      "\n",
      "\n",
      "Cinsiyete One-Hot Encoding yaparsak\n",
      "      fr   tr  usa    boy   kilo    yas  erkek  kiz\n",
      "0   0.0  1.0  0.0  130.0   30.0  10.00    1.0  0.0\n",
      "1   0.0  1.0  0.0  125.0   36.0  11.00    1.0  0.0\n",
      "2   0.0  1.0  0.0  135.0   34.0  10.00    0.0  1.0\n",
      "3   0.0  1.0  0.0  133.0   30.0   9.00    0.0  1.0\n",
      "4   0.0  1.0  0.0  129.0   38.0  12.00    1.0  0.0\n",
      "5   0.0  1.0  0.0  180.0   90.0  30.00    1.0  0.0\n",
      "6   0.0  1.0  0.0  190.0   80.0  25.00    1.0  0.0\n",
      "7   0.0  1.0  0.0  175.0   90.0  35.00    1.0  0.0\n",
      "8   0.0  1.0  0.0  177.0   60.0  22.00    0.0  1.0\n",
      "9   0.0  0.0  1.0  185.0  105.0  33.00    1.0  0.0\n",
      "10  0.0  0.0  1.0  165.0   55.0  27.00    0.0  1.0\n",
      "11  0.0  0.0  1.0  155.0   50.0  44.00    0.0  1.0\n",
      "12  0.0  0.0  1.0  160.0   58.0  28.45    0.0  1.0\n",
      "13  0.0  0.0  1.0  162.0   59.0  41.00    0.0  1.0\n",
      "14  0.0  0.0  1.0  167.0   62.0  55.00    0.0  1.0\n",
      "15  1.0  0.0  0.0  174.0   70.0  47.00    1.0  0.0\n",
      "16  1.0  0.0  0.0  193.0   90.0  28.45    1.0  0.0\n",
      "17  1.0  0.0  0.0  187.0   80.0  27.00    1.0  0.0\n",
      "18  1.0  0.0  0.0  183.0   88.0  28.00    1.0  0.0\n",
      "19  1.0  0.0  0.0  159.0   40.0  29.00    0.0  1.0\n",
      "20  1.0  0.0  0.0  164.0   66.0  32.00    0.0  1.0\n",
      "21  1.0  0.0  0.0  166.0   56.0  42.00    0.0  1.0\n"
     ]
    }
   ],
   "source": [
    "#yaptığımız değişiklikleri datas verimize aktarıyoruz(one-hot encoding, label encoding işlemleri ve fit-transform ile yaptığımız\n",
    "#ortalama alıp nan değerleri doldurma işlemi) bunu dataframe oluşturarak yapıyoruz\n",
    "#dataframelerin dizilerden farkı, index ve column başlıklarının olması\n",
    "#Öncelikle ulke işlemlerini dataframe haline getirelim. 22 tane satır olduğu için index=22 yaptık\n",
    "df = pd.DataFrame(data=ulke, index=range(22), columns=['fr', 'tr', 'usa'])\n",
    "print(\"Ulkeler dfsi\\n\", df)\n",
    "\n",
    "#Şimdide yas kısmında nan değerleri doldurmuştuk, onların eklendiği sayısal değerler ile bir df oluşturalım\n",
    "df1 = pd.DataFrame(data=Yas, index=range(22), columns=['boy', 'kilo', 'yas'])\n",
    "print(\"\\n\\nBoy, Kilo, Yas dfsi\\n\",df1)\n",
    "\n",
    "#en sonunda ise en sondaki cinsiyet sütununu ele alan bir df oluşturalım\n",
    "cinsiyet1 = datas1.iloc[:, -1].values\n",
    "df2 = pd.DataFrame(data=cinsiyet1, index=range(22), columns=['cinsiyet'])\n",
    "print(\"\\n\\nCinsiyet dfsi\\n\", df2)\n",
    "\n",
    "#cinsiyet sütununu 1-0 olarak değiştirirsek ortaya çıkacak df:\n",
    "df3 = pd.DataFrame(data=cinsiyet, index=range(22), columns=['erkek', 'kiz'])\n",
    "print(\"\\n\\nCinsiyet OHE dfsi\\n\", df3)\n",
    "\n",
    "#En sonda ise oluşturduğumuz 3 farklı df'yi tek dfde birleştirelim\n",
    "sonucdf= pd.concat([df, df1, df2], axis=1)#concat df'leri birleştirmemize yarıyor. Axis=1 yapmamızın sebebi ise, yapmadığımız zaman\n",
    "#alt alta 2 tabloyu yazıyor ancak ilk df'de boy, kilo, yas değerleri yok ama ikinci df'de var, o yüzden o değerlere nan yazar\n",
    "#aynı şekilde ikinci df'de fr, tr, usa değerleri olmadığı için oralara nan yazar. Axis ile bu kolonları birleştiriyoruz ve\n",
    "#nan değer yazmasını engelleyip satırları eşliyoruz.\n",
    "\n",
    "#aşağıda kullanacağımız için tek seferde değil 2 seferde df'leri birleştirelim. Önce ulke ve boy, kilo, yas'ı birleştireceğiz\n",
    "#cinsiyet olmadan oluşturulan df\n",
    "sonuc1df = pd.concat([df, df1], axis=1)\n",
    "print(\"\\n\\nUlke ve Boy, Kilo, Yas dfsi\\n\", sonuc1df)\n",
    "\n",
    "\n",
    "#sonra ise üstte oluşturduğumuz df ile cinsiyet kolonunu birleştireceğiz\n",
    "sonuc2df = pd.concat([sonuc1df, df2], axis=1)\n",
    "print(\"\\n\\nBu dfye Cinsiyet eklenmiş halde son df\\n\", sonuc2df)\n",
    "\n",
    "\n",
    "sonuc3df = pd.concat([df, df1, df3], axis=1)#Cinsiyet One-Hot Endocing'i için bir df\n",
    "print(\"\\n\\nTek seferde oluşturulmuş df\\n\", sonucdf)\n",
    "print(\"\\n\\nCinsiyete One-Hot Encoding yaparsak\\n\", sonuc3df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fr   tr  usa    boy   kilo    yas\n",
      "8   0.0  1.0  0.0  177.0   60.0  22.00\n",
      "6   0.0  1.0  0.0  190.0   80.0  25.00\n",
      "16  1.0  0.0  0.0  193.0   90.0  28.45\n",
      "4   0.0  1.0  0.0  129.0   38.0  12.00\n",
      "2   0.0  1.0  0.0  135.0   34.0  10.00\n",
      "5   0.0  1.0  0.0  180.0   90.0  30.00\n",
      "17  1.0  0.0  0.0  187.0   80.0  27.00\n",
      "9   0.0  0.0  1.0  185.0  105.0  33.00\n",
      "7   0.0  1.0  0.0  175.0   90.0  35.00\n",
      "18  1.0  0.0  0.0  183.0   88.0  28.00\n",
      "3   0.0  1.0  0.0  133.0   30.0   9.00\n",
      "0   0.0  1.0  0.0  130.0   30.0  10.00\n",
      "15  1.0  0.0  0.0  174.0   70.0  47.00\n",
      "12  0.0  0.0  1.0  160.0   58.0  28.45\n",
      "\n",
      "\n",
      "      fr   tr  usa    boy  kilo   yas\n",
      "20  1.0  0.0  0.0  164.0  66.0  32.0\n",
      "10  0.0  0.0  1.0  165.0  55.0  27.0\n",
      "14  0.0  0.0  1.0  167.0  62.0  55.0\n",
      "13  0.0  0.0  1.0  162.0  59.0  41.0\n",
      "1   0.0  1.0  0.0  125.0  36.0  11.0\n",
      "21  1.0  0.0  0.0  166.0  56.0  42.0\n",
      "11  0.0  0.0  1.0  155.0  50.0  44.0\n",
      "19  1.0  0.0  0.0  159.0  40.0  29.0\n",
      "\n",
      "\n",
      "    cinsiyet\n",
      "8         k\n",
      "6         e\n",
      "16        e\n",
      "4         e\n",
      "2         k\n",
      "5         e\n",
      "17        e\n",
      "9         e\n",
      "7         e\n",
      "18        e\n",
      "3         k\n",
      "0         e\n",
      "15        e\n",
      "12        k\n",
      "\n",
      "\n",
      "    cinsiyet\n",
      "20        k\n",
      "10        k\n",
      "14        k\n",
      "13        k\n",
      "1         e\n",
      "21        k\n",
      "11        k\n",
      "19        k\n"
     ]
    }
   ],
   "source": [
    "#Veri kümesinin eğitim ve test olarak bölünme işlemi\n",
    "#Amacımız df'yi (ulke, boy, yas, kilo) - (cinsiyet) olarak ayırmak. Verimizi 4 parçaya böleceğiz\n",
    "#x = bağımsız değişkenler, y = bağımlı değişkenler, train ve test = verinin satır bazlı bölümü. Belli bir satıra kadar olanlar\n",
    "#train, kalanları test\n",
    "#bizim x train ve test(bağımsız) değişkenlerimiz = ulke, boy, kilo, yas\n",
    "#y train ve test(bağımlı) değişkenlerimiz cinsiyet(ohe yapılmamış!)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(sonuc1df, df2, test_size=0.33, random_state=0)\n",
    "#test_size demek yaklaşık %33'ü test için bölünecek(yani kabaca 7 si) kalanı train için bölünecek\n",
    "#random_state ise rassal sayı üreticisinin nereden başlayacağı\n",
    "print(x_train)\n",
    "print(\"\\n\\n\", x_test)\n",
    "print(\"\\n\\n\",y_train)\n",
    "print(\"\\n\\n\",y_test)\n",
    "#rastgele alınan satırlar ile bağımsız değişkenler gözüküyor ve y değerleri de bu değerlere karşılık gelen bağımlı değişkenler\n",
    "#test için 8 satır kullanılmış\n",
    "#yani veriyi öncelikle dikey eksende bağımlı ve bağımsız değişken olarak ayırıyoruz sonra da yatay eksende train ve test olarak ayırıyoruz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.63245553  0.8660254  -0.40824829  0.45049444 -0.29657884 -0.24717129]\n",
      " [-0.63245553  0.8660254  -0.40824829  1.00824945  0.5096549   0.03416189]\n",
      " [ 1.58113883 -1.15470054 -0.40824829  1.13696215  0.91277178  0.35769504]\n",
      " [-0.63245553  0.8660254  -0.40824829 -1.6089087  -1.18343596 -1.18494855]\n",
      " [-0.63245553  0.8660254  -0.40824829 -1.35148331 -1.34468271 -1.372504  ]\n",
      " [-0.63245553  0.8660254  -0.40824829  0.57920713  0.91277178  0.50305051]\n",
      " [ 1.58113883 -1.15470054 -0.40824829  0.87953676  0.5096549   0.22171734]\n",
      " [-0.63245553 -1.15470054  2.44948974  0.79372829  1.51744708  0.78438369]\n",
      " [-0.63245553  0.8660254  -0.40824829  0.36468597  0.91277178  0.97193914]\n",
      " [ 1.58113883 -1.15470054 -0.40824829  0.70791983  0.8321484   0.31549506]\n",
      " [-0.63245553  0.8660254  -0.40824829 -1.43729177 -1.50592946 -1.46628173]\n",
      " [-0.63245553  0.8660254  -0.40824829 -1.56600447 -1.50592946 -1.372504  ]\n",
      " [ 1.58113883 -1.15470054 -0.40824829  0.32178174  0.10653803  2.09727185]\n",
      " [-0.63245553 -1.15470054  2.44948974 -0.27887751 -0.37720222  0.35769504]]\n",
      "\n",
      "\n",
      " [[ 1.29099445 -0.37796447 -1.          0.47240026  1.32853794 -0.24991255]\n",
      " [-0.77459667 -0.37796447  1.          0.54952683  0.20439045 -0.64977262]\n",
      " [-0.77459667 -0.37796447  1.          0.70377998  0.91975703  1.58944379]\n",
      " [-0.77459667 -0.37796447  1.          0.31814711  0.61317136  0.46983559]\n",
      " [-0.77459667  2.64575131 -1.         -2.53553608 -1.73731884 -1.92932485]\n",
      " [ 1.29099445 -0.37796447 -1.          0.6266534   0.30658568  0.5498076 ]\n",
      " [-0.77459667 -0.37796447  1.         -0.2217389  -0.30658568  0.70975163]\n",
      " [ 1.29099445 -0.37796447 -1.          0.08676739 -1.32853794 -0.48982859]]\n"
     ]
    }
   ],
   "source": [
    "#Öznitelik Ölçekleme\n",
    "#Normalde bakarsak boylar arasında max-min olarak çok fark var, aynı şekilde yaş ve kiloda da bu durum geçerli\n",
    "#Biz burada bu aradaki farkı aza indirerek değerleri birbirine yaklaştırmaya, birbirine ölçeklemeye çalışacağız\n",
    "#Yani farklı dünyalarda olan veriler, aynı dünyaya çekiliyor\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(x_train)\n",
    "X_test = sc.fit_transform(x_test)\n",
    "print(X_train)\n",
    "print(\"\\n\\n\", X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
